#,Layer,File,Line/Function,Hardcoded Value,Category,Why Dangerous,Current Impact,Layers Affected,Recommendation,Why Needed
1,Frontend,OneMindAI.tsx,193-250,MODEL_TOKEN_LIMITS맖bject,游댮 CAT 1: Token Limits,Overrides database values,Admin panel settings ignored,"L1,L2, L6",Migrate to마i_models.max_output_tokens,Database-driven values allow runtime changes without deploy
2,Frontend,OneMindAI.tsx,260-340,BASE_PRICING맖bject,游리 CAT 2:Pricing,Duplicate of database data,Pricing맊hanges require code deploy,"L1, L2, L6","Remove, use맛seAIModels()맏ook only",Single맙ource of truth prevents pricing inconsistencies
3,Frontend,OneMindAI.tsx,389-402,PROVIDER_MAX_OUTPUT맖bject,游댮 CAT 1: TokenLimits,Ignores맗rovider_config.max_output_cap,Admin settings have맕o effect,"L1, L3, L4, L6",Wire맚o맗rovider_config.max_output_cap맜ia맛seAdminConfig(),Admin panel changes must마ffectㅁPI behavior
4,Frontend,OneMindAI.tsx,1625,MAX_PROMPT_LENGTH = 7000,游리 CAT 3: PromptLimits,Ignores맙ystem_config.max_prompt_length,Admin setting unused,"L1, L3, L6",Wire to맙ystem_config.max_prompt_length,Admins need ability맚o adjust prompt limits per deployment
5,Frontend,OneMindAI.tsx,1670-1677,BACKEND_CAPS맖bject,游댮CAT 1: Token Limits,Duplicates backend logic말n frontend,Frontend/backend mismatch,"L1, L3, L4","Delete만ntirely,맍etch맍rom backend response headers",Eliminates frontend/backend divergence and mismatch warnings
6,Frontend,OneMindAI.tsx,254,DEFAULT_TOKEN_LIMIT = 8192,游댮 CAT 1: Token Limits,Magic number fallback,Unknown models많et arbitrary맓imit,"L2, L3, L6",Keep as fallback but document in,"Fallback needed for unknown models, but should be centralized"
,,,,,,,,,useAIModels.ts,
7,Frontend,OneMindAI.tsx,"2038,2216,만tc.",temperature: 0.7(25+말nstances),游리 CAT 10: Temperature,Not맊onfigurable per provider,Users맊an't adjust creativity,"L1, L3, L4, L7","Add맋efault_temperature맚o맗rovider_config, centralize in helper",Allows per-provider temperature tuning without code맊hanges
8,Frontend,OneMindAI.tsx,409,|| 4096맍allback,游댮 CAT 1: Token Limits,Silent fallback,Unknown providers많et low limit,"L3, L4, L6",Use많etProviderMaxOutput()맏elper with logging,Silent맍allbacks hide configuration맍ailures
9,Frontend,OneMindAI.tsx,375,Math.round(((inTok + outTok) / 1000) * 3 + 2),游릭 CAT 4: TokenEstimation,Magic multipliers,Time estimates may막e wrong,L3,Extract맚o맙ystem_config.time_estimation_multiplier,Time estimates should be tunable based on real맗erformance맋ata
10,Frontend,OneMindAI.tsx,1093,"Math.min(1500, Math.max(300, ...))",游릭CAT 4: Token Estimation,Output estimation bounds,Cost만stimates may be wrong,L3,"Extract to맙ystem_config(min_output_estimate, max_output_estimate)",Cost estimates need tuning as맔odels evolve
11,Frontend,OneMindAI.tsx,"6573, 9458",excludedModels마rray,游릭CAT 8: UIConfig,Hardcoded model exclusions,Can't change망ithout deploy,"L1, L2",Add말s_live_streaming_supported막oolean맚o마i_models맚able,Feature마vailability should be configurable per맔odel
12,Frontend,useAdminConfig.ts,44-77,DEFAULT_SYSTEM_CONFIG마rray,游릭 CAT 15:Correct (Fallback),Necessary fallback,Acceptable pattern,"L2, L6",Keep as-is (fallback forDB unavailability),Fallback is necessary맍or resilience
13,Frontend,useAdminConfig.ts,68-77,DEFAULT_PROVIDER_CONFIG마rray,游릭 CAT 15:Correct (Fallback),Necessary fallback,Acceptable pattern,"L2, L6",Keep as-is (fallback for DB맛navailability),Fallback말s necessary for resilience
14,Frontend,useAdminConfig.ts,84,CACHE_DURATION_MS = 5 * 60 * 1000,游릭 CAT 6: Cache Duration,Should be configurable,5 min may막e too long/short,L2,Move to맙ystem_config.cache_duration_ms,Cache duration should be tunable for different deployment맙cenarios
15,Frontend,useAIModels.ts,58-72,FALLBACK_MODELS마rray,游릭 CAT 15: Correct (Fallback),Necessary fallback,Acceptable맗attern,"L2, L6",Keep as-is (fallback맍or DB unavailability),Fallback is necessary for resilience
16,Frontend,useAIModels.ts,79,CACHE_DURATION_MS = 5 * 60 * 1000,游릭 CAT 6: Cache Duration,Duplicate of #14,Inconsistency risk,L2,Consolidate with#14 in맙ystem_config,Prevents cache맋uration말nconsistencies between hooks
17,Frontend,proxy-client.ts,9,'http://localhost:3002'맍allback,游릭 CAT 11: Server Config,Dev URL in맗roduction code,Works but맕ot ideal,"L3, L4",Use말mport.meta.env.VITE_BACKEND_URL(already done),Environment variables separate config맍rom code
18,Frontend,proxy-client.ts,"66, 82,120, 136",temperature ?? 0.7,游리 CAT 10: Temperature,Repeated default,Should be centralized,"L3, L4, L7",Create많etDefaultTemperature(provider)맏elper,Centralization prevents inconsistent defaults across맊lients
19,Frontend,proxy-client.ts,"66, 83, 120, 137",max_tokens || 4000,游댮 CAT 1: Token Limits,Arbitrary fallback,May truncate responses,"L3, L4",Use많etProviderMaxOutput()맏elper,Arbitrary fallbacks causeresponse맚runcation
20,Frontend,balance-tracker.ts,23,'http://localhost:3001/api',游릭 CAT11: Server Config,Hardcoded devURL,Breaks말n production,L3,Use말mport.meta.env.VITE_BALANCE_API_URL,Environment variables required for production deployments
21,Frontend,balance-tracker.ts,28,CACHE_TTL = 5000,游릭 CAT 6: Cache Duration,5 second cache,May cause맙tale data,L3,Move맚o맙ystem_config.balance_cache_ttl_ms,Cache TTL should be tunable based on balance맛pdate맍requency
22,Frontend,error-recovery-engine.ts,378,15 * 60 * 1000(15 min throttle),游릭 CAT 7: APIConfig,Throttle duration,May be too long,"L3, L5",Move맚o맙ystem_config.throttle_duration_ms,Throttle duration needs tuning based on rate맓imit patterns
23,Frontend,error-recovery-engine.ts,385,"setTimeout(resolve, 5000)",游릭CAT 7: API Config,5 second wait,Arbitrary delay,L3,Move맚o맙ystem_config.error_recovery_wait_ms,Recovery delays should be configurable
24,Frontend,request-throttler.ts,50,1000(1 second window),游릭 CAT 7: API Config,Rate맓imit window,Should be configurable,"L3, L5",Move to맙ystem_config.rate_limit_window_ms,Rate limit windows need tuning per맗rovider
25,Frontend,request-throttler.ts,65,15 * 60 * 1000맋efault,游릭 CAT 7: API Config,Throttle duration,Duplicate맖f #22,"L3, L5",Consolidate with #22 in맙ystem_config,Prevents throttle duration inconsistencies
26,Frontend,streaming-client.ts,"54,76, 93,120",temperature || 0.7,游리 CAT10: Temperature,Repeated default,Should be centralized,"L3,L4, L7",Use centralized많etDefaultTemperature()맏elper,Centralization prevents inconsistent defaults
27,Frontend,universal-ai-client.ts,"96, 144, 184, 238",temperature || 0.7,游리 CAT 10: Temperature,Repeated default,Should be centralized,"L3, L4,L7",Use centralized많etDefaultTemperature()맏elper,Centralization prevents inconsistent defaults
28,Frontend,claude-client.ts,49,temperature || 0.7,游리 CAT 10: Temperature,Repeated default,Should be centralized,"L3, L4, L7",Use centralized많etDefaultTemperature()맏elper,Centralization맗revents inconsistent defaults
29,Frontend,super-debug-bus.ts,1151,> 10000(display truncation),游릭CAT 5: UI Thresholds,Display limit,May hide말mportant data,"L1, L3",Move to맙ystem_config.debug_display_max_chars,Debug맋isplay limits should be tunable
30,Frontend,super-debug-bus.ts,1210,> 5000(response맚runcation),游릭 CAT 5: UI Thresholds,Display맓imit,May hide important data,"L1, L3",Move to맙ystem_config.debug_response_max_chars,Debug display limits should be tunable
31,Frontend,FileUploadZone.tsx,"178, 600",'http://localhost:3005',游릭 CAT 11: Server Config,Echo IntelligenceURL,Hardcoded dev URL,"L1, L3, L7",Use말mport.meta.env.VITE_ECHO_INTELLIGENCE_URL,Environment variables required for feature URLs
32,Frontend,HubSpotModal.tsx,"128, 150",'http://localhost:3002/api/hubspot/...',游릭CAT 12: HubSpot,Hardcoded APIURLs,Breaks말n production,"L1, L3, L4,L7",Use말mport.meta.env.VITE_BACKEND_URL,Environment variables required for production
33,Frontend,HubSpotSendButton.tsx,43,'http://localhost:3002/api/hubspot/...',游릭 CAT 12: HubSpot,Hardcoded API URL,Breaks in production,"L1, L3, L4, L7",Use말mport.meta.env.VITE_BACKEND_URL,Environment variables required for production
34,Frontend,CreditPricingPanel.tsx,84,PROFIT_MARKUP = 0.30,游리CAT 2: Pricing,Business-critical markup,Should be in DB,"L1, L3, L6",Move to맙ystem_config.profit_markup_percentage,Business맔arkup must막e configurable without code맊hanges
35,Frontend,CreditPricingPanel.tsx,87,CREDITS_PER_USD = 100,游리 CAT 2: Pricing,Exchangerate,Should be in DB,"L1, L3, L6",Move to맙ystem_config.credits_per_usd,Exchange rates need tuning for맋ifferent markets
36,Frontend,core/constants.ts,186-251,BASE_PRICING맖bject,游리CAT 2: Pricing,Duplicate맖f OneMindAI.tsx,Two sources맖f truth,"L2,L6","Remove entirely,맛se맛seAIModels()맖nly",Eliminates pricing duplication and inconsistency
37,Frontend,core/constants.ts,33-180,SEEDED_ENGINES마rray,游릭 CAT 9: DefaultModels,Engine definitions,Acceptable for막ootstrap,L2,Keep as-is (bootstrap맋ata),Bootstrap data is necessary맍or initial마pp맓oad
38,Frontend,config/constants.ts,40-64,TOKENIZER_CONFIG,游릭 CAT 4: Token Estimation,Tokenizer ratios,"Empirically맋erived,OK",L3,Keep as-is (empirical constants),"Tokenizer ratios are mathematical constants, not configuration"
39,Frontend,Various,Multiple,"setTimeout(..., 3000)",游릭CAT 5: UI Thresholds,UI feedback맋elays,Low impact,L1,Keep마s-is (low말mpact),UI feedback delays are acceptable hardcoded values
40,Frontend,Various,Multiple,"setTimeout(..., 5000)",游릭 CAT 5: UI Thresholds,Warning auto-clear,Low impact,L1,Keep as-is (low impact),Warning auto-clear delays are acceptable hardcoded values
41,Backend,ai-proxy.cjs,25,CACHE_TTL = 5 * 60 * 1000,游릭 CAT 6: Cache Duration,Provider맊onfig cache,Should match frontend,"L4, L5",Consolidate with frontend cache duration말n맙ystem_config,Backend/frontend cache durations must막e synchronized
42,Backend,ai-proxy.cjs,46,PORT = 3002,游릭 CAT 11: Server Config,Server port,Uses env맜ar with fallback,"L4, L5",Keep마s-is (env var with fallback),Environment맜ariable fallback is acceptable pattern
43,Backend,ai-proxy.cjs,153,expires_in - 60(60s막uffer),游릭 CAT 7: API Config,Tokenrefresh buffer,Magic맕umber,"L4, L7",Move맚o맙ystem_config.token_refresh_buffer_seconds,Tokenrefresh buffer should be tunable
44,Backend,ai-proxy.cjs,908,8192맍allback for anthropic,游댮 CAT 1: TokenLimits,Fallback limit,May not match마dmin setting,"L4, L5, L6,L7",Fetch맍rom맗rovider_config.max_output_cap망ith fallback,Backend mustrespect admin-configured token맓imits
45,Backend,ai-proxy.cjs,1017,8192맍allback for gemini,游댮 CAT 1: Token Limits,Fallback limit,May not match마dmin setting,"L4, L5, L6, L7",Fetch from맗rovider_config.max_output_cap망ith fallback,Backend must respect admin-configured token limits
46,Backend,ai-proxy.cjs,1019,temperature: 0.7,游리 CAT 10: Temperature,Default temperature,Not configurable,"L4, L5, L7",Add맋efault_temperature맚o맗rovider_config,Backend temperature맔ust match맍rontend configuration
47,Backend,ai-proxy-improved.cjs,26,PORT = 3002,游릭 CAT 11: Server Config,Server port,Uses env var,"L4, L5",Keep마s-is (env var),Environment variable is마cceptable pattern
48,Backend,ai-proxy-improved.cjs,38,RATE_LIMIT_WINDOW_MS = 60 * 1000,游릭 CAT 7: API Config,Rate limit window,Uses env var,L5,Keep as-is (env var),Environment variable is acceptable pattern
49,Backend,ai-proxy-improved.cjs,39,RATE_LIMIT_MAX = 60,游릭 CAT7: API Config,Rate limit max,Uses env var,L5,Keep as-is (env맜ar),Environment variable is acceptable pattern
50,Backend,code-guardian/llm-judge.cjs,144,maxContentLength = 8000,游릭 CAT 3: Prompt Limits,Content truncation,Code Guardian맙pecific,"L4, L5",Keep as-is (Code Guardian specific),CodeGuardian has independent맊onfiguration needs
51,Backend,code-guardian/llm-judge.cjs,"190,246",temperature: 0.3,游리 CAT 10: Temperature,Lower temp맍or judging,Intentional for consistency,"L4, L7",Keep as-is (intentional for consistency),Lower맚emperature is intentional for code judgment
52,Backend,code-guardian/index.cjs,36,PORT = 4000,游릭CAT 11: Server Config,CodeGuardian port,Uses env var,"L4, L5",Keep as-is(env var),Environment variable is acceptable pattern
53,Backend,code-guardian/index.cjs,338,count = 100맋efault,游릭 CAT 7: API Config,Default query param,Low말mpact,L4,Keep as-is (low impact),Default query parameter말s acceptable
54,Backend,balance-api.cjs,14,PORT = 3001,游릭 CAT 11:Server Config,Balance API port,Should use env var,"L4,L5",Add env varBALANCE_API_PORT망ith맍allback,Environment variable required for production flexibility
55,Backend,server-monitor.cjs,43,RESTART_WINDOW = 60000,游릭 CAT 7: API Config,Restart window,Should be configurable,L5,Add env맜arRESTART_WINDOW_MS망ith맍allback,Restart window should be tunable per deployment
